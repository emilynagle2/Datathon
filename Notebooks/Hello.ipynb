{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb22927",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello World!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7c8a92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   STATUSID        STATUS\n",
      "0         1      Finished\n",
      "1         2  Disqualified\n",
      "2         3      Accident\n",
      "3         4     Collision\n",
      "4         5        Engine\n"
     ]
    }
   ],
   "source": [
    "import snowflake.connector\n",
    "import os\n",
    "import pandas as pd\n",
    "import dotenv as dot\n",
    "from sqlalchemy import create_engine\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "DATABASE_SCHEMA = \"EVENT.DATATHON_2025_TEAM_ETA\"\n",
    "\n",
    "def get_snowflake_connection():\n",
    "    \"\"\"\n",
    "    Create a connection to Snowflake using credentials from .env file\n",
    "    \"\"\"\n",
    "    # Load environment variables\n",
    "    dot.load_dotenv()\n",
    "    \n",
    "    # Get connection parameters from environment variables\n",
    "    conn = snowflake.connector.connect(\n",
    "        account=os.getenv(\"SNOWFLAKE_ACCOUNT\"),\n",
    "        user=os.getenv(\"SNOWFLAKE_USER\"),\n",
    "        password=os.getenv(\"SNOWFLAKE_PASSWORD\"),\n",
    "        role=os.getenv(\"SNOWFLAKE_ROLE\"),\n",
    "        warehouse=os.getenv(\"SNOWFLAKE_WAREHOUSE\"),\n",
    "        database=os.getenv(\"SNOWFLAKE_DATABASE\"),\n",
    "        schema=os.getenv(\"SNOWFLAKE_SCHEMA\")\n",
    "    )\n",
    "    \n",
    "    return conn\n",
    "\n",
    "def query_to_df(query):\n",
    "    \"\"\"\n",
    "    Execute a query and return the results as a pandas DataFrame\n",
    "    \"\"\"\n",
    "    conn = get_snowflake_connection()\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(query)\n",
    "\n",
    "    # Get column names\n",
    "    columns = [col[0] for col in cursor.description]\n",
    "\n",
    "    # Fetch all rows and convert to list of dictionaries\n",
    "    results = [dict(zip(columns, row)) for row in cursor.fetchall()]\n",
    "\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def upload_csv_to_snowflake(dataframe, table_name):\n",
    "    \n",
    "    conn = get_snowflake_connection()\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    engine = create_engine(\n",
    "        f'snowflake://{conn.user}:{os.getenv(\"SNOWFLAKE_PASSWORD\")}@{conn.account}/{conn.database}/{conn.schema}?warehouse={conn.warehouse}'\n",
    "    )\n",
    "    dataframe.to_sql(\n",
    "        name=table_name,\n",
    "        con=engine,\n",
    "        schema=conn.schema,\n",
    "        if_exists=\"replace\",\n",
    "        index=False,\n",
    "        method='multi'\n",
    "    )\n",
    "    \n",
    "    # Get row count\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(f\"SELECT COUNT(*) FROM {conn.database}.{conn.schema}.{table_name}\")\n",
    "    row_count = cursor.fetchone()[0]\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    \n",
    "    return row_count\n",
    "    \n",
    "\n",
    "# Example status_df \n",
    "status = query_to_df(f\"SELECT * FROM {DATABASE_SCHEMA}.status\")\n",
    "print(status.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c130f63b",
   "metadata": {},
   "source": [
    "TASK A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd9faff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RESULTID  RACEID  DRIVERID  CONSTRUCTORID  NUMBER  GRID  POSITION  \\\n",
      "0         1      18         1              1    22.0     1       1.0   \n",
      "1         2      18         2              2     3.0     5       2.0   \n",
      "2         3      18         3              3     7.0     7       3.0   \n",
      "3         4      18         4              4     5.0    11       4.0   \n",
      "4         5      18         5              1    23.0     3       5.0   \n",
      "\n",
      "  POSITIONTEXT  POSITIONORDER POINTS  ...  QUALI_TIME SPRINT_DATE  \\\n",
      "0            1              1   10.0  ...        None        None   \n",
      "1            2              2    8.0  ...        None        None   \n",
      "2            3              3    6.0  ...        None        None   \n",
      "3            4              4    5.0  ...        None        None   \n",
      "4            5              5    4.0  ...        None        None   \n",
      "\n",
      "   SPRINT_TIME          FULL_NAME         DOB NATIONALITY WINS  \\\n",
      "0         None     Lewis Hamilton  1985-01-07     British  105   \n",
      "1         None      Nick Heidfeld  1977-05-10      German    0   \n",
      "2         None       Nico Rosberg  1985-06-27      German   23   \n",
      "3         None    Fernando Alonso  1981-07-29     Spanish   32   \n",
      "4         None  Heikki Kovalainen  1981-10-19     Finnish    1   \n",
      "\n",
      "   CONSTRUCTOR_NAME  CONSTRUCTOR_NATIONALITY    STATUS  \n",
      "0           McLaren                  British  Finished  \n",
      "1        BMW Sauber                   German  Finished  \n",
      "2          Williams                  British  Finished  \n",
      "3           Renault                   French  Finished  \n",
      "4           McLaren                  British  Finished  \n",
      "\n",
      "[5 rows x 41 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a master dataset from drivers, races, constructors, status, results\n",
    "\n",
    "drivers = query_to_df(f\"SELECT * FROM {DATABASE_SCHEMA}.DRIVERS\")\n",
    "\n",
    "races = query_to_df(f\"SELECT * FROM {DATABASE_SCHEMA}.RACES\")\n",
    "races = races.rename(columns={'NAME': 'RACE_NAME'})\n",
    "\n",
    "constructors = query_to_df(f\"SELECT * FROM {DATABASE_SCHEMA}.CONSTRUCTORS\")\n",
    "constructors = constructors.rename(columns={'NAME': 'CONSTRUCTOR_NAME'})\n",
    "constructors = constructors.rename(columns={'NATIONALITY': 'CONSTRUCTOR_NATIONALITY'})\n",
    "\n",
    "results = query_to_df(f\"SELECT * FROM {DATABASE_SCHEMA}.RESULTS\")\n",
    "\n",
    "\n",
    "main_df = results.merge(races, on=\"RACEID\", suffixes=('', '_race')).merge(\n",
    "    drivers, \n",
    "    on=\"DRIVERID\", \n",
    "    suffixes=('', '_driver')\n",
    ").merge(\n",
    "    constructors, \n",
    "    on=\"CONSTRUCTORID\", \n",
    "    suffixes=('', '_constructor')\n",
    ").merge(\n",
    "    status, \n",
    "    on=\"STATUSID\", \n",
    "    suffixes=('', '_status')\n",
    ")\n",
    "\n",
    "print(main_df.head())\n",
    "\n",
    "# Upload to Snowflake\n",
    "row_count = upload_csv_to_snowflake(main_df, \"CONSTRUCTOR_DRIVER_RACE_STATUS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9d0cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 4 columns. New shape: (26759, 37)\n",
      "Dropped column POSITION from table\n",
      "Dropped column POSITIONTEXT from table\n",
      "Dropped column TIME from table\n",
      "Dropped column NUMBER from table\n",
      "Renamed column NATIONALITY to DRIVER_NATIONALITY in table\n",
      "Renamed column DOB to DRIVER_DOB in table\n",
      "Updated DataFrame shape: (26759, 36)\n",
      "   RESULTID  RACEID  DRIVERID  CONSTRUCTORID  GRID  POSITIONORDER POINTS  \\\n",
      "0         1      18         1              1     1              1   10.0   \n",
      "1         2      18         2              2     5              2    8.0   \n",
      "2         3      18         3              3     7              3    6.0   \n",
      "3         4      18         4              4    11              4    5.0   \n",
      "4         5      18         5              1     3              5    4.0   \n",
      "\n",
      "   LAPS  MILLISECONDS  FASTESTLAP  ...  QUALI_DATE QUALI_TIME SPRINT_DATE  \\\n",
      "0    58     5690616.0        39.0  ...        None       None        None   \n",
      "1    58     5696094.0        41.0  ...        None       None        None   \n",
      "2    58     5698779.0        41.0  ...        None       None        None   \n",
      "3    58     5707797.0        58.0  ...        None       None        None   \n",
      "4    58     5708630.0        43.0  ...        None       None        None   \n",
      "\n",
      "   SPRINT_TIME          FULL_NAME  DRIVER_DOB  DRIVER_NATIONALITY  \\\n",
      "0         None     Lewis Hamilton  1985-01-07             British   \n",
      "1         None      Nick Heidfeld  1977-05-10              German   \n",
      "2         None       Nico Rosberg  1985-06-27              German   \n",
      "3         None    Fernando Alonso  1981-07-29             Spanish   \n",
      "4         None  Heikki Kovalainen  1981-10-19             Finnish   \n",
      "\n",
      "  CONSTRUCTOR_NAME CONSTRUCTOR_NATIONALITY    STATUS  \n",
      "0          McLaren                 British  Finished  \n",
      "1       BMW Sauber                  German  Finished  \n",
      "2         Williams                 British  Finished  \n",
      "3          Renault                  French  Finished  \n",
      "4          McLaren                 British  Finished  \n",
      "\n",
      "[5 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "# Now we've created the big dataset, let's drop columns we don't need\n",
    "\n",
    "columns_to_drop = ['POSITION', 'POSITIONTEXT','TIME', 'NUMBER']\n",
    "columns_to_rename = [{'old': 'NATIONALITY', 'new': 'DRIVER_NATIONALITY'}, {'old':'DOB', 'new': 'DRIVER_DOB'}]\n",
    "\n",
    "# Drop columns from the DataFrame\n",
    "main_df_cleaned = main_df.drop(columns=columns_to_drop, errors='ignore')\n",
    "print(f\"Dropped {len(columns_to_drop)} columns. New shape: {main_df_cleaned.shape}\")\n",
    "\n",
    "\n",
    "conn = get_snowflake_connection()\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Drop columns from the existing table\n",
    "for column in columns_to_drop:\n",
    "    try:\n",
    "        cursor.execute(f\"ALTER TABLE {DATABASE_SCHEMA}.CONSTRUCTOR_DRIVER_RACE_STATUS DROP COLUMN IF EXISTS {column}\")\n",
    "        print(f\"Dropped column {column} from table\")\n",
    "    except:\n",
    "        print(f\"Column {column} not found or could not be dropped\")\n",
    "\n",
    "# Rename columns from the existing table for clarity\n",
    "for column in columns_to_rename:\n",
    "    try:\n",
    "        cursor.execute(f\"ALTER TABLE {DATABASE_SCHEMA}.CONSTRUCTOR_DRIVER_RACE_STATUS RENAME COLUMN {column['old']} TO {column['new']}\")\n",
    "        print(f\"Renamed column {column['old']} to {column['new']} in table\")\n",
    "    except:\n",
    "        print(f\"Column {column['old']} not found or could not be renamed\")\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "# Query the updated table to refresh the DataFrame\n",
    "main_df_updated = query_to_df(f\"SELECT * FROM {DATABASE_SCHEMA}.CONSTRUCTOR_DRIVER_RACE_STATUS\")\n",
    "print(f\"Updated DataFrame shape: {main_df_updated.shape}\")\n",
    "print(main_df_updated.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3596dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total races: 26759\n",
      "DNF races: 19086\n",
      "Finished races: 7673\n"
     ]
    }
   ],
   "source": [
    "# DNF column\n",
    "\n",
    "main_df_updated = query_to_df(f\"SELECT * FROM {DATABASE_SCHEMA}.CONSTRUCTOR_DRIVER_RACE_STATUS\")\n",
    "\n",
    "# Create DNF column based on multiple criteria\n",
    "main_df_updated['DNF'] = (\n",
    "    (main_df_updated['STATUSID'] != 1) |\n",
    "    # Time-based criteria\n",
    "    (main_df_updated['MILLISECONDS'].isnull()) |\n",
    "    # Lap-based criteria (requires groupby to get max laps per race)\n",
    "    main_df_updated.apply(lambda row: row['LAPS'] < \n",
    "                         main_df_updated[main_df_updated['RACEID'] == row['RACEID']]['LAPS'].max() * 0.9, \n",
    "                         axis=1)\n",
    ")\n",
    "\n",
    "# Print statistics\n",
    "print(f\"Total races: {len(main_df_updated)}\")\n",
    "print(f\"DNF races: {main_df_updated['DNF'].sum()}\")\n",
    "print(f\"Finished races: {len(main_df_updated) - main_df_updated['DNF'].sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed33dc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add DNF Col to Snowflake\n",
    "\n",
    "# Update the table in Snowflake\n",
    "conn = get_snowflake_connection()\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Update the table with the DNF values\n",
    "cursor.execute(f\"ALTER TABLE {DATABASE_SCHEMA}.CONSTRUCTOR_DRIVER_RACE_STATUS ADD COLUMN DNF BOOLEAN\")\n",
    "cursor.execute(f\"\"\"\n",
    "    UPDATE {DATABASE_SCHEMA}.CONSTRUCTOR_DRIVER_RACE_STATUS \n",
    "    SET DNF = CASE \n",
    "        WHEN STATUSID = 1 AND MILLISECONDS IS NOT NULL THEN FALSE \n",
    "        ELSE TRUE \n",
    "    END\n",
    "\"\"\")\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4be360de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CIRCUITID                            NAME  ESTIMATED_LENGTH_KM  \\\n",
      "0          1  Albert Park Grand Prix Circuit             5.294655   \n",
      "1          2    Sepang International Circuit             5.543338   \n",
      "2          3   Bahrain International Circuit             5.267601   \n",
      "3          4  Circuit de Barcelona-Catalunya             4.659043   \n",
      "4          5                   Istanbul Park             5.337986   \n",
      "\n",
      "   AVG_RACE_LAPS  ESTIMATED_RACE_DISTANCE_KM  \n",
      "0      57.666667                  305.325103  \n",
      "1      56.000000                  310.426914  \n",
      "2      59.416667                  312.983291  \n",
      "3      66.000000                  307.496857  \n",
      "4      58.000000                  309.603212  \n"
     ]
    }
   ],
   "source": [
    "# Playing about with circuits\n",
    "\n",
    "BOUNDARY_YEAR = 2014\n",
    "circuits = query_to_df(f\"SELECT * FROM {DATABASE_SCHEMA}.CIRCUITS\")\n",
    "\n",
    "winner_laps = results[results['POSITIONORDER'] == 1].groupby('RACEID')['LAPS'].max().reset_index()\n",
    "winner_laps = winner_laps.merge(races[['RACEID', 'CIRCUITID', 'YEAR']], on='RACEID')\n",
    "winner_laps = winner_laps[winner_laps['YEAR'] >= BOUNDARY_YEAR]\n",
    "\n",
    "fastest_laps = results.dropna(subset=['FASTESTLAPTIME', 'FASTESTLAPSPEED'])\n",
    "fastest_laps = fastest_laps.merge(races[['RACEID', 'CIRCUITID', 'YEAR']], on='RACEID')\n",
    "fastest_laps = fastest_laps[fastest_laps['YEAR'] >= BOUNDARY_YEAR]\n",
    "\n",
    "\n",
    "def lap_time_to_seconds(time):\n",
    "    if(pd.isna(time)):\n",
    "        return None\n",
    "    try:\n",
    "        parts = time.split(':')\n",
    "        return float(parts[0]) * 60 + float(parts[1])\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Apply the conversion\n",
    "fastest_laps['lap_time_seconds'] = fastest_laps['FASTESTLAPTIME'].apply(lap_time_to_seconds)\n",
    "fastest_laps['FASTESTLAPSPEED'] = fastest_laps['FASTESTLAPSPEED'].astype(float)\n",
    "fastest_laps['circuit_length_km'] = (fastest_laps['FASTESTLAPSPEED'] * fastest_laps['lap_time_seconds'] / 3600)\n",
    "\n",
    "circuit_lengths = fastest_laps.groupby('CIRCUITID')['circuit_length_km'].mean().reset_index()\n",
    "circuit_lengths = circuit_lengths.rename(columns={'circuit_length_km': 'ESTIMATED_LENGTH_KM'})\n",
    "circuit_laps = winner_laps.groupby('CIRCUITID')['LAPS'].mean().reset_index()\n",
    "circuit_laps = circuit_laps.rename(columns={'LAPS': 'AVG_RACE_LAPS'})\n",
    "\n",
    "# Merge circuit information\n",
    "enhanced_circuits = circuits.merge(circuit_lengths, on='CIRCUITID', how='left')\n",
    "enhanced_circuits = enhanced_circuits.merge(circuit_laps, on='CIRCUITID', how='left')\n",
    "\n",
    "# Calculate estimated race distance\n",
    "enhanced_circuits['ESTIMATED_RACE_DISTANCE_KM'] = enhanced_circuits['ESTIMATED_LENGTH_KM'] * enhanced_circuits['AVG_RACE_LAPS']\n",
    "\n",
    "# Display the enhanced circuits data\n",
    "print(enhanced_circuits[['CIRCUITID', 'NAME', 'ESTIMATED_LENGTH_KM', 'AVG_RACE_LAPS', 'ESTIMATED_RACE_DISTANCE_KM']].head())\n",
    "\n",
    "\n",
    "conn = get_snowflake_connection()\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Add new columns to the circuits table if they don't exist\n",
    "cursor.execute(f\"ALTER TABLE {DATABASE_SCHEMA}.CIRCUITS ADD COLUMN IF NOT EXISTS ESTIMATED_LENGTH_KM FLOAT\")\n",
    "cursor.execute(f\"ALTER TABLE {DATABASE_SCHEMA}.CIRCUITS ADD COLUMN IF NOT EXISTS AVG_RACE_LAPS FLOAT\")\n",
    "cursor.execute(f\"ALTER TABLE {DATABASE_SCHEMA}.CIRCUITS ADD COLUMN IF NOT EXISTS ESTIMATED_RACE_DISTANCE_KM FLOAT\")\n",
    "\n",
    "# Update the circuits table with the calculated values\n",
    "for _, row in enhanced_circuits.iterrows():\n",
    "    if pd.notna(row['ESTIMATED_LENGTH_KM']):\n",
    "        cursor.execute(f\"\"\"\n",
    "            UPDATE {DATABASE_SCHEMA}.CIRCUITS\n",
    "            SET \n",
    "                ESTIMATED_LENGTH_KM = {row['ESTIMATED_LENGTH_KM']},\n",
    "                AVG_RACE_LAPS = {row['AVG_RACE_LAPS'] if pd.notna(row['AVG_RACE_LAPS']) else 'NULL'},\n",
    "                ESTIMATED_RACE_DISTANCE_KM = {row['ESTIMATED_RACE_DISTANCE_KM'] if pd.notna(row['ESTIMATED_RACE_DISTANCE_KM']) else 'NULL'}\n",
    "            WHERE CIRCUITID = {row['CIRCUITID']}\n",
    "        \"\"\")\n",
    "\n",
    "cursor.close()\n",
    "conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".emily_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
